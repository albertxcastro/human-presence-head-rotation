{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# CNN Regressor for Head Pose Estimation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Jupyter notebook demonstrates the process of building a Convolutional Neural Network (CNN) regressor to estimate head pose angles (yaw, pitch, and roll) from images. The model is trained using a sub-dataset derived from the 300W-LP dataset, specifically focusing on the head position attributes.\n",
    "\n",
    "## Dataset Preparation\n",
    "\n",
    "### Dataset Source\n",
    "The original dataset used is the [300W-LP dataset](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm). It contains various features, but for this project, only the head position attributes (yaw, pitch, roll) were extracted.\n",
    "\n",
    "### Dataset Generation\n",
    "A subset of the 300W-LP dataset was created using the notebook provided in this [gist](https://gist.github.com/mani3/1ec02066cb11df85cfc694cab9230bc3#file-generate-dataset-from-the300w-lp-public-ipynb). This notebook extracts the relevant head position features and prepares the data for training.\n",
    "\n",
    "A subset of the new generated dataset is used. The regressor model is trained using only yaw angle values. \n",
    "\n",
    "### Dataset Splitting\n",
    "The dataset was split into three subsets:\n",
    "- **Training Set**: 60%\n",
    "- **Testing Set**: 20%\n",
    "- **Validation Set**: 20%\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "The CNN regressor is built using the following architecture:\n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(512, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "    \n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=MeanSquaredError(),\n",
    "              metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0664f7352be51",
   "metadata": {},
   "source": [
    "# Import all the neccesary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e49774cb9e5ffd6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-18T04:43:12.546042Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# for tensorflow install https://developer.apple.com/metal/tensorflow-plugin/\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b0a95ccdf0188b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T04:38:00.351919Z",
     "start_time": "2024-08-18T04:38:00.282803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 128, 128, 3)\n",
      "(20000, 3)\n"
     ]
    }
   ],
   "source": [
    "# load the preprocessed dataset \n",
    "with open('../dataset/data_20000.npy', 'rb') as data, open('../dataset/label_20000.npy', 'rb') as label:\n",
    "  dataset = np.load(data)\n",
    "  print(dataset.shape)\n",
    "  labels = np.load(label)\n",
    "  print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adfb21c046009b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
